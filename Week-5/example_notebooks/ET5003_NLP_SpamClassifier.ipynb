{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('et5003': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "ET5003_NLP_SpamClassifier.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "597b03594f35869c58876e9008f9a586d3b25b5bdb518ec8cfdc4f97486ff2d0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div>\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\r\n",
        "</div> \r\n",
        "\r\n",
        "# **Artificial Intelligence - MSc**\r\n",
        "## ET5003 - MACHINE LEARNING APPLICATIONS \r\n",
        "\r\n",
        "### Instructor: Enrique Naredo\r\n",
        "### ET5003_NLP_SpamClasiffier"
      ],
      "metadata": {
        "id": "930vlW5BrOtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Spam Classification"
      ],
      "metadata": {
        "id": "rQyc5Xgdj7W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Spamming](https://en.wikipedia.org/wiki/Spamming) is the use of messaging systems to send multiple unsolicited messages (spam) to large numbers of recipients for the purpose of commercial advertising, for the purpose of non-commercial proselytizing, for any prohibited purpose (especially the fraudulent purpose of phishing), or simply sending the same message over and over to the same user. "
      ],
      "metadata": {
        "id": "1z8j0PtO77Xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spam Classification: Deciding whether an email is spam or not.\n",
        "\n"
      ],
      "metadata": {
        "id": "b_fap_t2DrME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Wg7VCbX77eAA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# standard libraries\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\r\n",
        "\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.stem import SnowballStemmer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.cm import get_cmap\r\n",
        "from jupyterthemes import jtplot as jt\r\n",
        "\r\n",
        "jt.style()\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "%load_ext lab_black"
      ],
      "outputs": [],
      "metadata": {
        "id": "k96-GLUGE2ux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load dataset"
      ],
      "metadata": {
        "id": "-4iXKNAGj7W_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# path to your (local/cloud) drive\r\n",
        "path = os.path.join(os.getcwd(), \"spam.csv\")\r\n",
        "\r\n",
        "# load dataset\r\n",
        "df = pd.read_csv(path, encoding=\"latin-1\")\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {
        "id": "5akGy2kSj7W_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# remove useless features\r\n",
        "df = df.drop(\r\n",
        "    [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=\"columns\", errors=\"ignore\"\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "MODwpwEkJGky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# v1 -> is the class label: ham, spam\r\n",
        "# ham -> https://en.wiktionary.org/wiki/ham_e-mail\r\n",
        "# spam -> https://en.wiktionary.org/wiki/spam#English\r\n",
        "# v2 -> is the  email\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "id": "oDvr4HpKGZlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Pre-processing"
      ],
      "metadata": {
        "id": "wMyuPYcuj7XB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Removing stopwords and stemming\r\n",
        "# a stem must be a word\r\n",
        "# Example:  fishing, fished, and fisher: stem -> fish\r\n",
        "# choose English as the target language\r\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gmTe13CNKS_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Stop words are basically a set of commonly used words in any language\r\n",
        "# https://en.wikipedia.org/wiki/Stop_word\r\n",
        "# and are filtered out before processing of natural language data\r\n",
        "# Example list: https://github.com/igorbrigadir/stopwords/blob/master/en/terrier.txt\r\n",
        "nltk.download(\"stopwords\")\r\n",
        "stop = set(stopwords.words(\"english\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\gamin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "metadata": {
        "id": "qNG-xh8wMOTi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# example: remove anything that is not a letter\r\n",
        "string_sample = \"123This @45is 890-130 an_example !!\"\r\n",
        "new_string = re.sub(\"[^a-zA-Z]\", \" \", string_sample)\r\n",
        "print(new_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   This    is         an example   \n"
          ]
        }
      ],
      "metadata": {
        "id": "Q3mbvmBFO310"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# removing duplicated spaces\r\n",
        "\" \".join(new_string.split())"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is an example'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "id": "riD32a4VSQPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# remove anything that is not a letter in the emails\r\n",
        "df[\"v2_clean\"] = [re.sub(\"[^a-zA-Z]\", \" \", sms) for sms in df[\"v2\"]]\r\n",
        "df.sample(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v2_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>ham</td>\n",
              "      <td>Tell them no need to investigate about me anyw...</td>\n",
              "      <td>Tell them no need to investigate about me anyw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4694</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! Your Mobile No 07808726822 was awarded...</td>\n",
              "      <td>URGENT  Your Mobile No             was awarded...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>ham</td>\n",
              "      <td>tap &amp; spile at seven. * Is that pub on gas st ...</td>\n",
              "      <td>tap   spile at seven    Is that pub on gas st ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>ham</td>\n",
              "      <td>Today is ACCEPT DAY..U Accept me as? Brother S...</td>\n",
              "      <td>Today is ACCEPT DAY  U Accept me as  Brother S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>ham</td>\n",
              "      <td>U sleeping now.. Or you going to take? Haha.. ...</td>\n",
              "      <td>U sleeping now   Or you going to take  Haha   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1                                                 v2  \\\n",
              "1488   ham  Tell them no need to investigate about me anyw...   \n",
              "4694  spam  URGENT! Your Mobile No 07808726822 was awarded...   \n",
              "3265   ham  tap & spile at seven. * Is that pub on gas st ...   \n",
              "3913   ham  Today is ACCEPT DAY..U Accept me as? Brother S...   \n",
              "1456   ham  U sleeping now.. Or you going to take? Haha.. ...   \n",
              "\n",
              "                                               v2_clean  \n",
              "1488  Tell them no need to investigate about me anyw...  \n",
              "4694  URGENT  Your Mobile No             was awarded...  \n",
              "3265  tap   spile at seven    Is that pub on gas st ...  \n",
              "3913  Today is ACCEPT DAY  U Accept me as  Brother S...  \n",
              "1456  U sleeping now   Or you going to take  Haha   ...  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "id": "sF15oylkN_UD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# list of words in the emails\r\n",
        "email_words = [sms.split() for sms in df[\"v2_clean\"]]\r\n",
        "print(email_words[:5])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Go', 'until', 'jurong', 'point', 'crazy', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'Cine', 'there', 'got', 'amore', 'wat'], ['Ok', 'lar', 'Joking', 'wif', 'u', 'oni'], ['Free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'FA', 'Cup', 'final', 'tkts', 'st', 'May', 'Text', 'FA', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 'T', 'C', 's', 'apply', 'over', 's'], ['U', 'dun', 'say', 'so', 'early', 'hor', 'U', 'c', 'already', 'then', 'say'], ['Nah', 'I', 'don', 't', 'think', 'he', 'goes', 'to', 'usf', 'he', 'lives', 'around', 'here', 'though']]\n"
          ]
        }
      ],
      "metadata": {
        "id": "Ujye-Z_GNcKm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# function to normalize words\r\n",
        "def normalize(words):\r\n",
        "    normalized_words = list()\r\n",
        "    for word in words:\r\n",
        "        # remove  the most common words\r\n",
        "        if word.lower() not in stop:\r\n",
        "            # stemming\r\n",
        "            new_word = stemmer.stem(word)\r\n",
        "            # lower case\r\n",
        "            normalized_words.append(new_word.lower())\r\n",
        "    return normalized_words"
      ],
      "outputs": [],
      "metadata": {
        "id": "bCzsxUkXj7XB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# normalize words in emails\r\n",
        "email_words_norm = [normalize(word) for word in email_words]\r\n",
        "print(email_words_norm[:3])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['go', 'jurong', 'point', 'crazi', 'avail', 'bugi', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amor', 'wat'], ['ok', 'lar', 'joke', 'wif', 'u', 'oni'], ['free', 'entri', 'wkli', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'receiv', 'entri', 'question', 'std', 'txt', 'rate', 'c', 'appli']]\n"
          ]
        }
      ],
      "metadata": {
        "id": "ACEku-N6Tag9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "# update dataframe\r\n",
        "df[\"v2_normalized\"] = [\" \".join(word) for word in email_words_norm]\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v2_clean</th>\n",
              "      <th>v2_normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>Go until jurong point  crazy   Available only ...</td>\n",
              "      <td>go jurong point crazi avail bugi n great world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar    Joking wif u oni</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>Free entry in   a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entri wkli comp win fa cup final tkts st ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so early hor    U c already then say</td>\n",
              "      <td>u dun say earli hor u c alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>Nah I don t think he goes to usf  he lives aro...</td>\n",
              "      <td>nah think goe usf live around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...   \n",
              "1   ham                      Ok lar... Joking wif u oni...   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3   ham  U dun say so early hor... U c already then say...   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                            v2_clean  \\\n",
              "0  Go until jurong point  crazy   Available only ...   \n",
              "1                      Ok lar    Joking wif u oni      \n",
              "2  Free entry in   a wkly comp to win FA Cup fina...   \n",
              "3  U dun say so early hor    U c already then say      \n",
              "4  Nah I don t think he goes to usf  he lives aro...   \n",
              "\n",
              "                                       v2_normalized  \n",
              "0  go jurong point crazi avail bugi n great world...  \n",
              "1                              ok lar joke wif u oni  \n",
              "2  free entri wkli comp win fa cup final tkts st ...  \n",
              "3                u dun say earli hor u c alreadi say  \n",
              "4               nah think goe usf live around though  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "id": "rBNa4IlTgUef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# training and test datasets\r\n",
        "data_register = df[\"v2_normalized\"]\r\n",
        "class_label = df[\"v1\"]\r\n",
        "factor = 0.2\r\n",
        "lucky_number = 7\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(\r\n",
        "    data_register, class_label, test_size=factor, random_state=lucky_number\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "mUSE99a6j7XC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# train\r\n",
        "print(x_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4459    wish great day moji told offer alway speechles...\n",
            "1921                               current food alon also\n",
            "5255                                       ok sweet dream\n",
            "5507                               want insid everi night\n",
            "356     congratul ur award cd voucher gift guarante fr...\n",
            "                              ...                        \n",
            "4307                         ha ha pop loo hello ed hello\n",
            "2550                  pleas sen kind advic pleas come tri\n",
            "537                     mayb fat finger press button know\n",
            "1220    nokia tone ur mob everi week txt nok st tone f...\n",
            "4271                                                  get\n",
            "Name: v2_normalized, Length: 4457, dtype: object\n"
          ]
        }
      ],
      "metadata": {
        "id": "M7N04_o7iVCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# test\r\n",
        "print(x_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83                                              place man\n",
            "2235    si como listen plaid album quit gd new air hil...\n",
            "2746                                  k da mani page want\n",
            "246                                           ask call ok\n",
            "3120                small problem auction punj ask tiwari\n",
            "                              ...                        \n",
            "2460                        cant talk call dont keep call\n",
            "2661                                        know dad back\n",
            "2086                                  dude like buff wind\n",
            "5126    wonder okor great month cherish guy wish well ...\n",
            "2886                                          k take care\n",
            "Name: v2_normalized, Length: 1115, dtype: object\n"
          ]
        }
      ],
      "metadata": {
        "id": "j0_UqNlqi62U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# class labels in training\r\n",
        "y_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4459     ham\n",
              "1921     ham\n",
              "5255     ham\n",
              "5507     ham\n",
              "356     spam\n",
              "        ... \n",
              "4307     ham\n",
              "2550     ham\n",
              "537      ham\n",
              "1220    spam\n",
              "4271     ham\n",
              "Name: v1, Length: 4457, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "id": "ttq_X1YHjY1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# reshape -> gives a new shape to an array without changing its data\r\n",
        "# https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.reshape.html#numpy.reshape\r\n",
        "# -1 -> the unspecified value is inferred\r\n",
        "y_train.values.reshape(-1, 1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['ham'],\n",
              "       ['ham'],\n",
              "       ['ham'],\n",
              "       ...,\n",
              "       ['ham'],\n",
              "       ['spam'],\n",
              "       ['ham']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {
        "id": "AD7KRHWsj7XC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build your custome function**"
      ],
      "metadata": {
        "id": "T8NL5aZ4fb0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The real difference between stemming and lemmatization is that stemming reduces word-forms to (pseudo) stems which might be meaningful or meaningless, whereas lemmatization reduces the word-forms to linguistically valid meaning."
      ],
      "metadata": {
        "id": "USUzEMJSW5WL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# you can build your own NLP function\r\n",
        "# edit it according to your requirements\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.stem.porter import *\r\n",
        "\r\n",
        "nltk.download(\"punkt\")\r\n",
        "nltk.download(\"wordnet\")\r\n",
        "\r\n",
        "\r\n",
        "def NLP_preprocess(some_text):\r\n",
        "    \"\"\"\r\n",
        "  Normalization using NLTK and spaCy\r\n",
        "  \"\"\"\r\n",
        "    # 1. Tokenization\r\n",
        "    NLP_token = word_tokenize(some_text)\r\n",
        "\r\n",
        "    # 2. Stemming\r\n",
        "    PS = PorterStemmer()\r\n",
        "    NLP_stem = []\r\n",
        "    for word in NLP_token:\r\n",
        "        NLP_stem.append(PS.stem(word))\r\n",
        "    # 3. Lemmatization\r\n",
        "    WL = WordNetLemmatizer()\r\n",
        "    NLP_lemma = []\r\n",
        "    for word in NLP_stem:\r\n",
        "        NLP_lemma.append(WL.lemmatize(word))\r\n",
        "    # 4. Stopword\r\n",
        "    FS = []\r\n",
        "    NLP_stop = set(stopwords.words(\"english\"))\r\n",
        "    for w in NLP_lemma:\r\n",
        "        if w not in NLP_stop:\r\n",
        "            FS.append(w)\r\n",
        "    # 5. Punctuation\r\n",
        "    punctuations = \"?:!.,;\"\r\n",
        "    for word in FS:\r\n",
        "        if word in punctuations:\r\n",
        "            FS.remove(word)\r\n",
        "    # print comparison\r\n",
        "    print(\" \")\r\n",
        "    print(some_text)\r\n",
        "    print(FS)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\gamin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\gamin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "metadata": {
        "id": "7h5pJ9tNWEJn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# example\r\n",
        "NLP_preprocess(string_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "123This @45is 890-130 an_example !!\n",
            "['123thi', '@', '45i', '890-130', 'an_exampl', '!']\n"
          ]
        }
      ],
      "metadata": {
        "id": "Yzxo1AWSWFTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Counts"
      ],
      "metadata": {
        "id": "rpnCzn7Jj7XD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create new features with NLP**"
      ],
      "metadata": {
        "id": "1kcKwXjDJ5ES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# Convert a collection of text documents to a matrix of token counts\r\n",
        "CV = CountVectorizer()"
      ],
      "outputs": [],
      "metadata": {
        "id": "UWzId1JpmOYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "## training\r\n",
        "# transforming email into counts\r\n",
        "# counting the number of times a word appears in each email\r\n",
        "# 'x_train_count' is a sparse matrix, this avoids to store the zeroes\r\n",
        "x_train_count = CV.fit_transform(x_train)\r\n",
        "\r\n",
        "# returns: n_samples, n_features\r\n",
        "print(\"total emails =\", x_train_count.shape[0])\r\n",
        "print(\"total words =\", x_train_count.shape[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total emails = 4457\n",
            "total words = 5595\n"
          ]
        }
      ],
      "metadata": {
        "id": "-m30-9q5mwYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# show the counts in train\r\n",
        "print(x_train_count)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5405)\t1\n",
            "  (0, 1991)\t2\n",
            "  (0, 1140)\t1\n",
            "  (0, 3047)\t1\n",
            "  (0, 4944)\t1\n",
            "  (0, 3328)\t2\n",
            "  (0, 162)\t1\n",
            "  (0, 4483)\t1\n",
            "  (0, 1398)\t1\n",
            "  (0, 1921)\t1\n",
            "  (0, 2676)\t1\n",
            "  (0, 458)\t1\n",
            "  (0, 4620)\t1\n",
            "  (0, 1552)\t1\n",
            "  (0, 3214)\t1\n",
            "  (0, 1790)\t1\n",
            "  (0, 2541)\t1\n",
            "  (0, 4984)\t1\n",
            "  (0, 4456)\t1\n",
            "  (1, 1089)\t1\n",
            "  (1, 1734)\t1\n",
            "  (1, 150)\t1\n",
            "  (1, 156)\t1\n",
            "  (2, 3342)\t1\n",
            "  (2, 4701)\t1\n",
            "  :\t:\n",
            "  (4453, 74)\t1\n",
            "  (4454, 2580)\t1\n",
            "  (4454, 1623)\t1\n",
            "  (4454, 2920)\t1\n",
            "  (4454, 1681)\t1\n",
            "  (4454, 3715)\t1\n",
            "  (4454, 683)\t1\n",
            "  (4455, 1529)\t1\n",
            "  (4455, 5150)\t2\n",
            "  (4455, 1776)\t1\n",
            "  (4455, 5065)\t1\n",
            "  (4455, 1885)\t1\n",
            "  (4455, 4786)\t1\n",
            "  (4455, 1792)\t1\n",
            "  (4455, 3249)\t1\n",
            "  (4455, 3960)\t1\n",
            "  (4455, 2160)\t1\n",
            "  (4455, 2341)\t1\n",
            "  (4455, 5327)\t1\n",
            "  (4455, 4533)\t1\n",
            "  (4455, 4956)\t3\n",
            "  (4455, 3032)\t1\n",
            "  (4455, 5067)\t1\n",
            "  (4455, 3248)\t1\n",
            "  (4456, 1885)\t1\n"
          ]
        }
      ],
      "metadata": {
        "id": "BzOt7nuUrACv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "# full matrix\r\n",
        "x_train_count.toarray()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "metadata": {
        "id": "XrovMutirKZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "## test\r\n",
        "# transforming email into counts\r\n",
        "# counting the number of times a word appears in each email\r\n",
        "# using the vocabulary fitted with '.fit'\r\n",
        "# sparse matrix: only non-zeroes elements are stored\r\n",
        "x_test_count = CV.transform(x_test)\r\n",
        "\r\n",
        "# returns: n_samples, n_features\r\n",
        "print(\"total emails =\", x_test_count.shape[0])\r\n",
        "print(\"total words =\", x_test_count.shape[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total emails = 1115\n",
            "total words = 5595\n"
          ]
        }
      ],
      "metadata": {
        "id": "6yrAimS4j7XD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "# array mapping from feature integer indices to feature name\r\n",
        "int2feature = CV.get_feature_names()\r\n",
        "print(int2feature[:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aa', 'aah', 'aaniy', 'aaooooright', 'aathi', 'ab', 'abbey', 'abeg', 'aberdeen', 'abi']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\gamin\\anaconda3\\envs\\et5003\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "metadata": {
        "id": "lcxtAqZhrt8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# warning:\r\n",
        "# be aware that running several times next cell\r\n",
        "# it will append 'Class' each time\r\n",
        "c = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "fd50PJqPv1Np"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "# append 'Class' to the end of the list\r\n",
        "if c == 0:\r\n",
        "    int2feature.append(\"Class\")\r\n",
        "    # print last 10 feature names\r\n",
        "    print(int2feature[len(int2feature) - 10 : len(int2feature) - 1])\r\n",
        "    c = 1\r\n",
        "else:\r\n",
        "    print(\"already appended\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zed', 'zero', 'zf', 'zindgi', 'zoe', 'zogtorius', 'zouk', 'zs', 'zyada']\n"
          ]
        }
      ],
      "metadata": {
        "id": "1Z2mYaDqsgVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "# new dataset\r\n",
        "new_dataset = pd.DataFrame(\r\n",
        "    data=np.hstack([x_train_count.toarray(), y_train.values.reshape(-1, 1)]),\r\n",
        "    columns=int2feature,\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ISTJS6Gvj7XE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "# first rows\r\n",
        "new_dataset.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aah</th>\n",
              "      <th>aaniy</th>\n",
              "      <th>aaooooright</th>\n",
              "      <th>aathi</th>\n",
              "      <th>ab</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abeg</th>\n",
              "      <th>aberdeen</th>\n",
              "      <th>abi</th>\n",
              "      <th>...</th>\n",
              "      <th>zed</th>\n",
              "      <th>zero</th>\n",
              "      <th>zf</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zogtorius</th>\n",
              "      <th>zouk</th>\n",
              "      <th>zs</th>\n",
              "      <th>zyada</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5596 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  aa aah aaniy aaooooright aathi ab abbey abeg aberdeen abi  ... zed zero zf  \\\n",
              "0  0   0     0           0     0  0     0    0        0   0  ...   0    0  0   \n",
              "1  0   0     0           0     0  0     0    0        0   0  ...   0    0  0   \n",
              "2  0   0     0           0     0  0     0    0        0   0  ...   0    0  0   \n",
              "3  0   0     0           0     0  0     0    0        0   0  ...   0    0  0   \n",
              "4  0   0     0           0     0  0     0    0        0   0  ...   0    0  0   \n",
              "\n",
              "  zindgi zoe zogtorius zouk zs zyada Class  \n",
              "0      0   0         0    0  0     0   ham  \n",
              "1      0   0         0    0  0     0   ham  \n",
              "2      0   0         0    0  0     0   ham  \n",
              "3      0   0         0    0  0     0   ham  \n",
              "4      0   0         0    0  0     0  spam  \n",
              "\n",
              "[5 rows x 5596 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "metadata": {
        "id": "R3QXMdhIypsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "new_dataset.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aah</th>\n",
              "      <th>aaniy</th>\n",
              "      <th>aaooooright</th>\n",
              "      <th>aathi</th>\n",
              "      <th>ab</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abeg</th>\n",
              "      <th>aberdeen</th>\n",
              "      <th>abi</th>\n",
              "      <th>...</th>\n",
              "      <th>zed</th>\n",
              "      <th>zero</th>\n",
              "      <th>zf</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zogtorius</th>\n",
              "      <th>zouk</th>\n",
              "      <th>zs</th>\n",
              "      <th>zyada</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>...</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "      <td>4457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4456</td>\n",
              "      <td>4454</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4452</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4454</td>\n",
              "      <td>...</td>\n",
              "      <td>4452</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4455</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>4456</td>\n",
              "      <td>3855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 5596 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          aa   aah  aaniy  aaooooright  aathi    ab  abbey  abeg  aberdeen  \\\n",
              "count   4457  4457   4457         4457   4457  4457   4457  4457      4457   \n",
              "unique     2     2      2            2      2     2      2     2         2   \n",
              "top        0     0      0            0      0     0      0     0         0   \n",
              "freq    4456  4454   4456         4456   4452  4456   4456  4456      4456   \n",
              "\n",
              "         abi  ...   zed  zero    zf  zindgi   zoe  zogtorius  zouk    zs  \\\n",
              "count   4457  ...  4457  4457  4457    4457  4457       4457  4457  4457   \n",
              "unique     2  ...     2     2     2       2     2          2     2     2   \n",
              "top        0  ...     0     0     0       0     0          0     0     0   \n",
              "freq    4454  ...  4452  4456  4456    4456  4455       4456  4456  4456   \n",
              "\n",
              "        zyada  Class  \n",
              "count    4457   4457  \n",
              "unique      2      2  \n",
              "top         0    ham  \n",
              "freq     4456   3855  \n",
              "\n",
              "[4 rows x 5596 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "metadata": {
        "id": "Tqk2jRleyxd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "# write object to a comma-separated values (csv) file\r\n",
        "# verify in your folder\r\n",
        "new_dataset.to_csv(path[:-4] + \"_clean.csv\", index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "E8RoL4Z7uk62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data format"
      ],
      "metadata": {
        "id": "HyHnie_5j7XE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "# select an email number\r\n",
        "row_index = 0\r\n",
        "print(\"non-sparse matrix =\", x_train_count[row_index, :].todense())\r\n",
        "\r\n",
        "# original words in the email\r\n",
        "print(\"original words: \", x_train.values[row_index])\r\n",
        "\r\n",
        "# decoded numerical input\r\n",
        "DNI = x_train_count[row_index, :].todense()\r\n",
        "# inverse_transform: return terms per document with nonzero entries\r\n",
        "print(\"decoded input: \", CV.inverse_transform(DNI))\r\n",
        "\r\n",
        "# index of words\r\n",
        "ind = np.where(DNI[0, :] > 0)[1]\r\n",
        "print(\"word indexes: \", ind)\r\n",
        "\r\n",
        "# number of times those words appears in the email\r\n",
        "print(x_train_count[row_index, ind].todense())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non-sparse matrix = [[0 0 0 ... 0 0 0]]\n",
            "original words:  wish great day moji told offer alway speechless offer easili go great length behalf stun exam next friday keep touch sorri\n",
            "decoded input:  [array(['alway', 'behalf', 'day', 'easili', 'exam', 'friday', 'go',\n",
            "       'great', 'keep', 'length', 'moji', 'next', 'offer', 'sorri',\n",
            "       'speechless', 'stun', 'told', 'touch', 'wish'], dtype='<U34')]\n",
            "word indexes:  [ 162  458 1140 1398 1552 1790 1921 1991 2541 2676 3047 3214 3328 4456\n",
            " 4483 4620 4944 4984 5405]\n",
            "[[1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\gamin\\anaconda3\\envs\\et5003\\lib\\site-packages\\sklearn\\utils\\validation.py:590: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZdrMNE8jj7XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Learning"
      ],
      "metadata": {
        "id": "WGilAvtbj7XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the classifier and making predictions on the test set"
      ],
      "metadata": {
        "id": "m-KYhFh859c-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "# create a model\r\n",
        "MNB = MultinomialNB()\r\n",
        "\r\n",
        "# fit to data\r\n",
        "MNB.fit(x_train_count, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "metadata": {
        "id": "s9ZrtUKej7XF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "# testing the model\r\n",
        "\r\n",
        "prediction_train = MNB.predict(x_train_count)\r\n",
        "print(\"training prediction\\t\", prediction_train)\r\n",
        "\r\n",
        "prediction_test = MNB.predict(x_test_count)\r\n",
        "print(\"test prediction\\t\\t\", prediction_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training prediction\t ['ham' 'ham' 'ham' ... 'ham' 'spam' 'ham']\n",
            "test prediction\t\t ['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
          ]
        }
      ],
      "metadata": {
        "id": "YW7hoVB76Yqf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "# set_printoptions: If True, always print floating point numbers\r\n",
        "# using fixed point notation, in which case numbers equal to zero\r\n",
        "# in the current precision will print as zero\r\n",
        "np.set_printoptions(suppress=True)\r\n",
        "\r\n",
        "# Ham and Spam probabilities in test\r\n",
        "class_prob = MNB.predict_proba(x_test_count)\r\n",
        "print(class_prob)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99224585 0.00775415]\n",
            " [0.99710212 0.00289788]\n",
            " [0.99977543 0.00022457]\n",
            " ...\n",
            " [0.99721402 0.00278598]\n",
            " [0.99999219 0.00000781]\n",
            " [0.99364559 0.00635441]]\n"
          ]
        }
      ],
      "metadata": {
        "id": "wcAd5Wh6j7XG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "# show emails classified as 'spam'\r\n",
        "threshold = 0.5\r\n",
        "spam_ind = np.where(class_prob[:, 1] > threshold)[0]\r\n",
        "print(x_test.values[spam_ind][:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['know u u know send chat let find p msg rcvd hg suit land row w j hl ldn year'\n",
            " 'congrat nokia video camera phone call call cost ppm ave call min vari mobil close post bcm ldn wc n xx'\n",
            " 'dear dave final notic collect tenerif holiday cash award call landlin tcs sae box cw wx ppm'\n",
            " 'guarante award mayb even cash claim ur award call free legitimat efreefon number wat u think'\n",
            " 'free msg get gnarl barkley crazi rington total free repli go messag right'\n",
            " 'u get phone wanna chat set meet call u cum moro luv jane xx call minmoremobsemspobox po wa'\n",
            " 'congrat year special cinema pass call c suprman v matrix starwar etc free bx ip pm dont miss'\n",
            " 'congratul ur award either cd gift voucher free entri week draw txt music tncs www ldew com win ppmx age'\n",
            " 'hot live fantasi call p per min ntt ltd po box croydon cr wb k'\n",
            " 'sms ac sptv new jersey devil detroit red wing play ice hockey correct incorrect end repli end sptv']\n"
          ]
        }
      ],
      "metadata": {
        "id": "SqFxSVTzj7XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Accuracy"
      ],
      "metadata": {
        "id": "KkIb-_wUj7XG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "# accuracy in training set\r\n",
        "y_pred_train = prediction_train\r\n",
        "print(\"Train Accuracy: \" + str(accuracy_score(y_train, y_pred_train)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9923715503702042\n"
          ]
        }
      ],
      "metadata": {
        "id": "BjreL3sdj7XH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "# accuracy in test set (unseen data)\r\n",
        "y_true = y_test\r\n",
        "y_pred_test = prediction_test\r\n",
        "print(\"Test Accuracy: \" + str(accuracy_score(y_true, y_pred_test)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.989237668161435\n"
          ]
        }
      ],
      "metadata": {
        "scrolled": true,
        "id": "MQRTS8rTj7XH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "# confusion matrix\r\n",
        "conf_mat = confusion_matrix(y_true, y_pred_test)\r\n",
        "print(\"Confusion Matrix\\n\", conf_mat)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            " [[965   5]\n",
            " [  7 138]]\n"
          ]
        }
      ],
      "metadata": {
        "id": "Yqg3jqtWAPJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\r\n",
        "\r\n",
        "labels = [\"Ham\", \"Spam\"]\r\n",
        "\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "cax = ax.matshow(conf_mat)\r\n",
        "plt.title(\"Confusion matrix of the classifier\\n\")\r\n",
        "fig.colorbar(cax)\r\n",
        "ax.set_xticklabels([\"\"] + labels)\r\n",
        "ax.set_yticklabels([\"\"] + labels)\r\n",
        "plt.xlabel(\"Predicted\")\r\n",
        "plt.ylabel(\"True\")\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ipykernel_launcher:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "ipykernel_launcher:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "dark"
          }
        }
      ],
      "metadata": {
        "id": "ypc8HXCYEpNz"
      }
    }
  ]
}